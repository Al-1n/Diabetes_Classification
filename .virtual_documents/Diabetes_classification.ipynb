#!pip install optuna
#!pip install jupyterlab-optuna
#!pip install optuna-fast-fanova gunicorn
#!pip install imbalanced-learn
#!pip install hyperopt
#!pip install lightgbm
#!pip install catboost
#!pip install optuna-integration


import pandas as pd
import numpy as np
import seaborn as sns
import optuna
import matplotlib.pyplot as plt
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score
from sklearn.metrics import roc_curve, precision_recall_curve, classification_report, log_loss, roc_auc_score, confusion_matrix, recall_score
from IPython.display import Markdown, display
from ipywidgets import widgets, Layout
from IPython import display as disp
from hyperopt import hp, fmin, tpe, STATUS_OK, Trials, space_eval


# Define a function for printing using markdown
def printmd(string, color=None):
    colorstr = "<span style='color:{}'>{}</span>".format(color, string)
    display(Markdown(colorstr))

#Bold text delimiters
start_bold = "\033[1m"
end_bold = "\033[0;0m"

from xgboost import XGBClassifier
from catboost import CatBoostRegressor


#load the dataset and preview the first rows
df = pd.read_csv("./Data/diabetes.csv", sep = ",")

df.head()





#Verify that all columns have numeric types
df.dtypes


#Check the target variable label values
df["Outcome"].value_counts()


#Get the summary sttistics for all the columns
display(round(df.describe(), 3))


df.hist(bins = 30, figsize = (10, 10), color = 'orange')

plt.show()








# Define a function to extract information about missing measurements 
def print_missing_data_summary(df):
    '''
    This function will scan for missing values for different features and feature combinations at different steps of the imputation process.

    Symbol dicionary:
    
    N_GLU - Number of missing Glucose measurements 
    N_INS - Number of missing Insulin measurements
    N_BMI - Number of missing BMI measurements
    N_BPS - Number of missing Blood Pressure measurements
    N_STH - Number of missing Skin Thickness measurements     
    '''
    def printmd(string, color=None):
        colorstr = "<span style='color:{}'>{}</span>".format(color, string)
        display(Markdown(colorstr))  
    
    display(Markdown('---'))
    printmd(f"**N_GLU**: {df['Glucose'].isna().sum()}", color="#9DC183")
    printmd(f"**N_INS**: {df['Insulin'].isna().sum()}", color="#9DC183")
    printmd(f"**N_BMI**: {df['BMI'].isna().sum()}", color="#9DC183")
    printmd(f"**N_BPS**: {df['BloodPressure'].isna().sum()}", color="#9DC183")
    printmd(f"**N_STH**: {df['SkinThickness'].isna().sum()}", color="#9DC183")
    display(Markdown('---'))    

def render_widgets(num_widgets, titles, objects):
    # Create output widgets
    widgets_list = [widgets.Output() for _ in range(num_widgets)]
    
    # Render content in output widgets
    for i in range(num_widgets):
        with widgets_list[i]:
            # Display title in bold format
            title_html = "<b>{}</b>".format(titles[i])
            disp.display(disp.HTML(title_html))
            disp.display(objects[i])
    
    # Add CSS styles to distribute free space
    box_layout = Layout(display='flex',
                        flex_flow='row',
                        justify_content='flex-start',
                        width='auto'
                       )
    
    # Create Horizontal Box container
    hbox = widgets.HBox(widgets_list, layout=box_layout)
    
    # Render hbox
    disp.display(hbox)

#Define a function to summarize the classification metrics
def print_classification_metrics(model, x_train, y_train, x_test, y_test):

    #Define pointers for bold text formatting
    start_bold = "\033[1m"
    end_bold = "\033[0m"
    
    #print(start_bold + "Classification metrics" + end_bold)
    print()

    # performance of the trained model on the training set 
    train_result = model.score(x_train, y_train)

    # performance of the trained model using the testing set
    test_result = model.score(x_test, y_test)

    # make predictions on the training data
    y_train_predict = model.predict(x_train)     

    # make predictions on the test data
    y_predict = model.predict(x_test)

    # predict class probabilities on the training set
    y_train_predict_proba = model.predict_proba(x_train)

    # predict class probabilities on the test set
    y_predict_proba = model.predict_proba(x_test)

    # Calculate log loss for the training set
    log_loss_train = round(log_loss(y_train, y_train_predict_proba), 4)
    
    # Calculate log loss for the test set
    log_loss_value = round(log_loss(y_test, y_predict_proba), 4)

    # Calculate ROC AUC for the training set    
    roc_auc_train = roc_auc_score(y_train, y_train_predict_proba[:, 1])

    # Calculate ROC AUC for the test set    
    roc_auc = roc_auc_score(y_test, y_predict_proba[:, 1])

    # Calculate Precision-Recall score for the TRAINING set
    precision_train, recall_train, thresholds_train = precision_recall_curve(y_train, y_train_predict_proba[:, 1])

    # Define recall levels for interpolation
    recall_levels = np.linspace(0, 1, 100)

    # Interpolate precision values for each recall level
    interp_precision_train = np.interp(recall_levels, recall_train[::-1], precision_train[::-1])

    # Calculate AUPRC using the trapezoidal rule
    auprc_train = np.trapz(interp_precision_train, recall_levels)    
    
    # Calculate Precision-Recall score for the TEST set
    precision_test, recall_test, thresholds_test = precision_recall_curve(y_test, y_predict_proba[:, 1])

    # # Define recall levels for interpolation
    # recall_levels = np.linspace(0, 1, 100)

    # Interpolate precision values for each recall level
    interp_precision_test = np.interp(recall_levels, recall_test[::-1], precision_test[::-1])

    # Calculate AUPRC using the trapezoidal rule
    auprc_test = np.trapz(interp_precision_test, recall_levels)
    
    #display test performance metrics
    test_report = pd.DataFrame(classification_report(y_test,
                                                     y_predict,
                                                     digits=4,
                                                     output_dict = True)).transpose().astype(float).round(4).map("{:,.2f}".format)    
    
    add_test_metrics = pd.DataFrame([{'Log Loss': log_loss_value,
                                     'ROC AUC': round(roc_auc, 4),
                                     'AUPRC': round(auprc_test, 4)}], columns = ['Log Loss',
                                                                                 'ROC AUC',
                                                                                 'AUPRC']).transpose().rename(columns = {0: 'Score'})

    titles = ['Performance report', 'Additional metrics']
    render_widgets(2, titles, [test_report, add_test_metrics])    

    # Print the confusion matrix
    cm = confusion_matrix(y_test, y_predict)

    # Set the labels for the confusion matrix
    class_labels = ['Negative', 'Positive']  # Replace with your actual class labels
    
    # Create a heatmap with labels
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='RdGy', xticklabels=class_labels, yticklabels=class_labels)
    
    # Add labels and title
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Confusion Matrix')
    
    # Adjust the spacing between subplots
    plt.subplots_adjust(left=0.2, bottom=0.2)
    
    # Show the plot
    plt.show()


#display a pairplot to visualize correlations between feature pairs and feature distributions 
sns.pairplot(df, hue = 'Outcome', height = 1.5, corner = True, kind = 'scatter', diag_kind = 'hist')


cols = ["Glucose","Insulin","BMI","BloodPressure","SkinThickness"]
df[cols] = df[cols].replace({0: np.nan})

print_missing_data_summary(df)


# split the dataframe into target and features

y = df["Outcome"].copy() # target
X = df.drop(columns = ["Outcome"]).copy() # features

# Verify that the split was performed correctly
print(X.shape)
print(y.shape)


from sklearn.impute import SimpleImputer

imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean', copy = False)

cols = ["Glucose", "BMI", "BloodPressure"]
X[cols] = imp_mean.fit_transform(X[cols])

print_missing_data_summary(X)








cols = ["Glucose", "Insulin"]

y_train_imp = X[cols[1]].dropna()
X_train_imp = X.loc[y_train_imp.index, cols[0]].values.reshape(-1, 1)

# Define the hyperparameter search space
space = {
    'depth': hp.quniform('depth', 2, 10, 1), 
    'n_estimators': hp.choice('n_estimators', np.arange(100, 1001, dtype = int)),
    'learning_rate': hp.uniform('learning_rate', 0.0, 1.0),
    'max_leaves': hp.choice('max_leaves', np.arange(10, 65, dtype = int)),  
    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 0, 100),
    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1.0),
    'min_data_in_leaf': hp.uniform("min_data_in_leaf", 5, 100), 
    'subsample': hp.uniform('subsample', 0.5, 1.0),
    'random_strength': hp.quniform('random_strength', 1, 100, 1),
    }

# Define the objective function with early stopping
def catboost_objective(params):
    regressor = CatBoostRegressor(        
        objective = 'RMSE',        
        depth = int(params['depth']),
        iterations = int(params['n_estimators']),
        learning_rate = params['learning_rate'],
        max_leaves = int(params['max_leaves']),
        l2_leaf_reg = params['l2_leaf_reg'],
        colsample_bylevel = params['colsample_bylevel'],
        min_data_in_leaf = params['min_data_in_leaf'],
        subsample = params['subsample'],
        random_strength = int(params['random_strength']),        
        random_seed = 21,
        grow_policy = 'Lossguide',
        boosting_type = 'Plain',
        silent = True,
    )

    score = cross_val_score(regressor, 
                            X_train_imp,
                            y_train_imp, 
                            cv=5, 
                            scoring='neg_root_mean_squared_error',                             
                           )
    
    return {'loss': -score.mean(), 'status': STATUS_OK}
    
# Create a Trials object to track the optimization process
trials = Trials()

# Optimize the objective function using fmin
best = fmin(
    fn=catboost_objective,
    space=space,
    algo=tpe.suggest,
    max_evals=100,
    trials=trials,
    rstate=np.random.default_rng(21)
)

# Get the best hyperparameters
best_params = space_eval(space, best)

# Instantiate a Gradient Boosting Regressor with the best hyperparameters
gb_imputer = CatBoostRegressor(**best_params,
                           random_seed = 21,
                           grow_policy = 'Lossguide',
                           boosting_type = 'Plain',    
                           silent = True,                           
                           )

# Fit the imputer on your data
gb_imputer.fit(X_train_imp, y_train_imp)

y_missing_idx = X[cols[1]].isna()
X_new = X.loc[y_missing_idx, cols[0]].values.reshape(-1, 1)

# Predict missing values
y_predict = gb_imputer.predict(X_new)

# Update the original DataFrame with predicted values
X.loc[y_missing_idx, cols[1]] = y_predict

print_missing_data_summary(X)


cols = ["BMI", "SkinThickness"]

y_train_imp = X[cols[1]].dropna()
X_train_imp = X.loc[y_train_imp.index, cols[0]].values.reshape(-1, 1)

# Define the hyperparameter search space
space = {
    'depth': hp.quniform('depth', 2, 10, 1), 
    'n_estimators': hp.choice('n_estimators', np.arange(100, 1001, dtype = int)),
    'learning_rate': hp.uniform('learning_rate', 0.0, 1.0),
    'max_leaves': hp.choice('max_leaves', np.arange(10, 65, dtype = int)),  
    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 0, 100),
    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1.0),
    'min_data_in_leaf': hp.uniform("min_data_in_leaf", 5, 100), 
    'subsample': hp.uniform('subsample', 0.5, 1.0),
    'random_strength': hp.quniform('random_strength', 1, 100, 1),
    }

# Define the objective function with early stopping
def catboost_objective(params):
    regressor = CatBoostRegressor(        
        objective = 'RMSE',        
        depth = int(params['depth']),
        iterations = int(params['n_estimators']),
        learning_rate = params['learning_rate'],
        max_leaves = int(params['max_leaves']),
        l2_leaf_reg = params['l2_leaf_reg'],
        colsample_bylevel = params['colsample_bylevel'],
        min_data_in_leaf = params['min_data_in_leaf'],
        subsample = params['subsample'],
        random_strength = int(params['random_strength']),        
        random_seed = 21,
        grow_policy = 'Lossguide',
        boosting_type = 'Plain',
        silent = True,
    )

    score = cross_val_score(regressor, 
                            X_train_imp,
                            y_train_imp, 
                            cv=5, 
                            scoring='neg_root_mean_squared_error',                             
                           )
    
    return {'loss': -score.mean(), 'status': STATUS_OK}
    
# Create a Trials object to track the optimization process
trials = Trials()

# Optimize the objective function using fmin
best = fmin(
    fn=catboost_objective,
    space=space,
    algo=tpe.suggest,
    max_evals=100,
    trials=trials,
    rstate=np.random.default_rng(21)
)

# Get the best hyperparameters
best_params = space_eval(space, best)

# Instantiate a Gradient Boosting Regressor with the best hyperparameters
gb_imputer = CatBoostRegressor(**best_params,
                           random_seed = 21,
                           grow_policy = 'Lossguide',
                           boosting_type = 'Plain',    
                           silent = True,                           
                           )

# Fit the imputer on your data
gb_imputer.fit(X_train_imp, y_train_imp)

y_missing_idx = X[cols[1]].isna()
X_new = X.loc[y_missing_idx, cols[0]].values.reshape(-1, 1)

# Predict missing values
y_predict = gb_imputer.predict(X_new)

# Update the original DataFrame with predicted values
X.loc[y_missing_idx, cols[1]] = y_predict

print_missing_data_summary(X)


# Create a correlation matrix
corr_matrix = X.corr()

# Plot the correlation matrix
sns.set_context('talk')

plt.figure(figsize = (10, 10))

_ = sns.heatmap(corr_matrix, annot = True, fmt = ".3f", linewidths = .5)

plt.show()


df1 = df.dtypes.copy()
df2 = X.dtypes


titles = ['Original dtypes', 'New dtypes' ]
render_widgets(2, titles, [df1, df2])


cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'Age']

X[cols] = X[cols].astype(int)

X.dtypes


from collections import Counter

counter = Counter(y)
print(counter)


# estimate scale_pos_weight value
estimate = counter[0] / counter[1]
print('Estimate: %.3f' % estimate)


# split the labels and features into training and testing sets

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 21, stratify = y)

# Verify that the split was performed correctly
print('Training set')
print(X_train.shape)
print(y_train.shape)
print()
print('Testing set')
print(X_test.shape)
print(y_test.shape)
print()


# Verify that the index has been shuffled
print(X.index)
print()
print(X_train.index)


X_train.columns


from sklearn.preprocessing import MinMaxScaler

# Create a StandardScaler object
scaler = MinMaxScaler()

# Fit and transform the training data
X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)

# Transform the test data (using the same scaling parameters as the training data)
X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)

display(pd.DataFrame(X_train_scaled).head())

print()

display(X_train.head())





#Build a classifier with minimum parameters
xgb_classifier = XGBClassifier(objective = 'binary:logistic', 
                               eval_metric = 'logloss', 
                               scale_pos_weight = 1.866,
                               )
#Train the model
xgb_classifier.fit(X_train, y_train)





print_classification_metrics(xgb_classifier, X_train, y_train, X_test, y_test)





#Build a classifier with minimum parameters
xgb_classifier = XGBClassifier(objective = 'binary:logistic', 
                               eval_metric = 'logloss',
                               scale_pos_weight = 1.866,
                               )

xgb_classifier.fit(X_train_scaled, y_train)

# predict the performance score of the trained model using the testing dataset
print_classification_metrics(xgb_classifier, X_train_scaled, y_train, X_test_scaled, y_test)








# Reload the unprocessed dataset
df_raw = pd.read_csv("./Data/diabetes.csv", sep = ",")

# split the unprocessed data into target and features

y_raw = df_raw["Outcome"] # target
X_raw = df_raw.drop(columns = ["Outcome"]) # features

# split the data into train and test sets
X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size = 0.33, random_state = 21, stratify = y_raw)

#Build a classifier with minimum parameters
xgb_classifier = XGBClassifier(objective = 'binary:logistic', 
                               eval_metric = 'logloss', 
                               scale_pos_weight = 1.866,
                               )

#Fit the classifier to the raw data
xgb_classifier.fit(X_train_raw, y_train_raw)

# predict the performance score of the trained model using the testing dataset
print_classification_metrics(xgb_classifier, X_train_raw, y_train_raw, X_test_raw, y_test_raw)





from imblearn.over_sampling import SMOTE
from collections import Counter

sm = SMOTE(sampling_strategy = 'minority',
           random_state = 21,
           k_neighbors = 6,
           )

X_res, y_res = sm.fit_resample(X_train_scaled, y_train)
print()
print('Original dataset shape %s' % Counter(y_train))
print()
print('Resampled dataset shape %s' % Counter(y_res))
print()


#Build a classifier with minimum parameters
xgb_classifier = XGBClassifier(objective = 'binary:logistic', 
                               eval_metric = 'logloss',                            
                               )

#Fit the classifier to the raw data
xgb_classifier.fit(X_res, y_res)

# predict the performance score of the trained model using the testing dataset
print_classification_metrics(xgb_classifier, X_res, y_res, X_test_scaled, y_test)





selected_features = SelectKBest(chi2, k = 6).fit(X_res, y_res)

print('Score List: ', selected_features.scores_)
print()
print('Feature list: ', X_res.columns)


X_train_best = pd.DataFrame(selected_features.transform(X_res))

X_test_best = pd.DataFrame(selected_features.transform(X_test_scaled))

display(X_train_best.head())
display(X_train_scaled.head())





X_train_best = X_train_best.rename(columns = {0: 'Pregnancies', 1: 'Glucose', 2: 'Insulin', 3: 'BMI', 4: 'DPF', 5: 'Age'})
X_test_best = X_test_best.rename(columns = {0: 'Pregnancies', 1: 'Glucose', 2: 'Insulin', 3: 'BMI', 4: 'DPF', 5: 'Age'})

#Build a classifier with minimum parameters
xgb_classifier = XGBClassifier(objective = 'binary:logistic', 
                               eval_metric = 'logloss',                                                           
                               )

#Fit the classifier to the raw data
xgb_classifier.fit(X_train_best, y_res)

# predict the performance score of the trained model using the testing dataset
print_classification_metrics(xgb_classifier, X_train_best, y_res, X_test_best, y_test)


from sklearn.model_selection import StratifiedKFold

# Create a StratifiedKFold object
# skf = StratifiedKFold(n_splits=5,
#                       shuffle=True,
#                       random_state=21)

def strat_objective(trial):    
    # Define the hyperparameter search space
    max_depth = trial.suggest_int('max_depth', 3, 10)
    n_estimators = trial.suggest_int('n_estimators', 100, 1000)
    learning_rate = trial.suggest_float('learning_rate', 0.0, 5e-1, log=False)
    max_leaves = trial.suggest_int('max_leaves', 0, 64)
    min_child_weight = trial.suggest_int('min_child_weight', 1, 10)    
    subsample = trial.suggest_float('subsample', 0.5, 1.0)
    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)
    reg_alpha = trial.suggest_float('reg_alpha', 1e-8, 100, log=False)
    reg_lambda = trial.suggest_float('reg_lambda', 1e-8, 100, log=False)
    eval_metric = trial.suggest_categorical("eval_metric", ['logloss',"error", "aucpr", 'error@0.6'])
    scale_pos_weight = trial.suggest_float('scale_pos_weight', 1.0, 1.870)  

    # Create the XGBClassifier with the sampled hyperparameters
    classifier = XGBClassifier(
        max_depth = max_depth,
        n_estimators = n_estimators,
        learning_rate = learning_rate,
        max_leaves = max_leaves,
        min_child_weight=min_child_weight,        
        subsample = subsample,
        colsample_bytree = colsample_bytree,
        reg_alpha = reg_alpha,
        reg_lambda = reg_lambda,
        scale_pos_weight = scale_pos_weight,
        eval_metric = eval_metric,
        objective = 'binary:logistic',        
        grow_policy = 'lossguide',        
        use_label_encoder = False,
        seed = 21,
        n_jobs = -1,        
    )
    
    scores = cross_val_score(classifier, 
                             X_train_best, 
                             y_res,
                             cv=5,
                             scoring='average_precision',
                             verbose = False, n_jobs=-1)
    #return -scores.mean()
    return scores.mean()

# Create an Optuna study
study = optuna.create_study(direction='maximize')

# Optimize the objective function
optuna.logging.set_verbosity(optuna.logging.WARNING)
study.optimize(strat_objective, n_trials=100, timeout = 600, show_progress_bar = True)

# Print the best hyperparameters and the corresponding score
print()
print('Best hyperparameters: ', pd.DataFrame([study.best_params]).transpose())
print()
print('Best score (Minimum loss): ', study.best_value)
print()


best_params = study.best_params

xgb_classifier_opt = XGBClassifier(**best_params,
                                   objective = 'binary:logistic',
                                   grow_policy = 'lossguide',
                                   use_label_encoder = False,
                                   seed = 21,
                                   n_jobs = -1).fit(X_train_best, y_res, verbose = 0)

print_classification_metrics(xgb_classifier_opt, X_train_best, y_res, X_test_best, y_test)





from hyperopt import hp, fmin, tpe, STATUS_OK, Trials
from sklearn.model_selection import cross_val_score

# Define the hyperparameter search space
space = {
    'max_depth': hp.choice('max_depth', np.arange(2, 11, dtype = int)), 
    'n_estimators': hp.choice('n_estimators', np.arange(100, 1001, dtype = int)), 
    'learning_rate': hp.uniform('learning_rate', 1e-3, 5e-1),
    'max_leaves': hp.choice('max_leaves', np.arange(10, 65, dtype = int)),
    'subsample': hp.uniform('subsample', 0.5, 1.0),
    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 11, dtype = int)),    
    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),
    'reg_alpha': hp.uniform('reg_alpha', 1e-8, 1.0),
    'reg_lambda': hp.uniform('reg_lambda', 1e-8, 1.0),
}

# Define the objective function to optimize
def objective(params):
    classifier = XGBClassifier(
        max_depth = int(params['max_depth']),
        n_estimators = int(params['n_estimators']),
        learning_rate = params['learning_rate'],
        max_leaves = int(params['max_leaves']),
        min_child_weight = int(params['min_child_weight']),        
        subsample = params['subsample'],
        colsample_bytree = params['colsample_bytree'],
        reg_alpha = params['reg_alpha'],
        reg_lambda = params['reg_lambda'],
        objective = 'binary:logistic',        
        use_label_encoder = False,
        seed = 21,        
    )

    score = cross_val_score(classifier, 
                            X_train_best, y_res, 
                            cv=5, 
                            scoring='neg_log_loss',                            
                           )
    
    return {'loss': -score.mean(), 'status': STATUS_OK}

# Create a Trials object to track the optimization process
trials = Trials()

# Optimize the objective function using fmin
best = fmin(
    fn=objective,
    space=space,
    algo=tpe.suggest,
    max_evals=100,
    trials=trials,
    rstate=np.random.default_rng(21)
)

# Print the best hyperparameters and the corresponding score
print()
print("Best hyperparameters:", pd.DataFrame([best]).transpose())
print()
print("Best score (Minimum loss):", trials.best_trial['result']['loss'])


# # Retrieve the best hyperparameters
# best_params = trials.best_trial['misc']['vals']

# # Extract scalar values from the lists
# max_depth = int(best_params['max_depth'][0])
# n_estimators = int(best_params['n_estimators'][0])
# learning_rate = best_params['learning_rate'][0]
# min_child_weight = int(best_params['min_child_weight'][0])
# max_leaves = best_params['max_leaves'][0]
# colsample_bytree = best_params['colsample_bytree'][0]
# subsample = best_params['subsample'][0]
# reg_alpha = best_params['reg_alpha'][0]
# reg_lambda = best_params['reg_lambda'][0]

# xgb_classifier_hyp = XGBClassifier(objective = 'binary:logistic',                                     
#                                    learning_rate = learning_rate,
#                                    max_depth = max_depth,
#                                    max_leaves = max_leaves,
#                                    n_estimators = n_estimators,                
#                                    min_child_weight = min_child_weight,
#                                    subsample = subsample,
#                                    colsample_bytree = colsample_bytree,
#                                    reg_alpha = reg_alpha,
#                                    reg_lambda = reg_lambda,                                 
#                                    scale_pos_weight = 1.853,
#                                    use_label_encoder = False,
#                                    seed = 21).fit(X_train_best, y_res, verbose = 0)

# Get the best hyperparameters
best_params = space_eval(space, best)

xgb_classifier_hyp = XGBClassifier(objective = 'binary:logistic',                                     
                                   **best_params,                                
                                   scale_pos_weight = 1.853,
                                   use_label_encoder = False,
                                   seed = 21).fit(X_train_best, y_res, verbose = 0)

print_classification_metrics(xgb_classifier_hyp, X_train_best, y_res, X_test_best, y_test)





import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import average_precision_score

# LightGBM with Stratified K-Fold Cross-Validation
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)

# Define the objective function for LightGBM
def lgb_objective(trial):
    params = {        
        'objective': 'binary',        
        'max_depth': trial.suggest_int('max_depth', 2, 10),
        'num_leaves': trial.suggest_int('num_leaves', 10, 64),
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 5e-1, log=False),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 11),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=False),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=False),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'random_state': 21,
        #'n_jobs': -1, 
        'verbosity': -1,
    }

    scores = cross_val_score(lgb.LGBMClassifier(**params), 
                             X_train_best, y_res, 
                             cv=skf, 
                             scoring='neg_log_loss', 
                             #n_jobs=-1
                            )
    return -scores.mean()

# Create an Optuna study
study = optuna.create_study(direction='minimize')

# Optimize the objective function
optuna.logging.set_verbosity(optuna.logging.WARNING)
study.optimize(lgb_objective, 
               n_trials=100, 
               timeout = 600, 
               show_progress_bar = True)

# Print the best hyperparameters and the corresponding score
print()
print("Best hyperparameters:", pd.DataFrame([study.best_params]).transpose())
print()
print("Best score (Minimum loss):", study.best_value)
print()





# Train the LightGBM model with the best hyperparameters
best_params = study.best_params
lgb_model = lgb.LGBMClassifier(**best_params, verbosity = -1)
lgb_model.fit(X_train_best, y_res)

print_classification_metrics(lgb_model, X_train_best, y_res, X_test_best, y_test)


import lightgbm as lgb
import warnings
from hyperopt import hp, fmin, tpe, STATUS_OK, Trials
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import average_precision_score
import sklearn

# LightGBM with Stratified K-Fold Cross-Validation
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)

# Define the hyperparameter search space
space = {        
    'max_depth': hp.choice('max_depth', np.arange(2, 11, dtype = int)),
    'n_estimators': hp.choice('n_estimators', np.arange(100, 1001, dtype = int)),
    'learning_rate': hp.uniform('learning_rate', 1e-3, 5e-1),
    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 11, dtype = int)),
    'num_leaves': hp.choice('num_leaves', np.arange(10, 65, dtype = int)),
    'subsample': hp.uniform('subsample', 0.5, 1.0),
    'min_child_samples': hp.choice('min_child_samples', np.arange(5, 101, dtype = int)),
    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),
    'reg_alpha': hp.uniform('reg_alpha', 1e-8, 1.0),
    'reg_lambda': hp.uniform('reg_lambda', 1e-8, 1.0),
}

# Define the objective function to optimize
def objective(params):    
    classifier = lgb.LGBMClassifier(        
        objective = 'binary',
        max_depth = int(params['max_depth']),
        n_estimators = int(params['n_estimators']),
        learning_rate = params['learning_rate'],
        min_child_weight = int(params['min_child_weight']),        
        subsample = params['subsample'],
        colsample_bytree = params['colsample_bytree'],
        reg_alpha = params['reg_alpha'],
        reg_lambda = params['reg_lambda'],
        is_unbalance = True,                
        seed = 21,
        #n_jobs = -1,
        verbosity = -1,
    )
    
    score = cross_val_score(classifier, 
                            X_train_best, y_res, 
                            cv=skf, 
                            scoring='neg_log_loss', 
                            #n_jobs=-1
                           )
    return {'loss': -score.mean(), 'status': STATUS_OK}

# Create a Trials object to track the optimization process
trials = Trials()

# Optimize the objective function using fmin
best = fmin(
    fn=objective,
    space=space,
    algo=tpe.suggest,
    max_evals=100,
    trials=trials,
    rstate=np.random.default_rng(21)
)

# Print the best hyperparameters and the corresponding score
print()
print("Best hyperparameters:", pd.DataFrame([best]).transpose())
print()
print("Best score (Minimum loss):", trials.best_trial['result']['loss'])


# Retrieve the best hyperparameters
best_params = trials.best_trial['misc']['vals']

# Extract scalar values from the lists
max_depth = int(best_params['max_depth'][0])
n_estimators = int(best_params['n_estimators'][0])
learning_rate = best_params['learning_rate'][0]
min_child_weight = int(best_params['min_child_weight'][0])
min_child_samples = int(best_params['min_child_samples'][0])
num_leaves = int(best_params['num_leaves'][0]) 
colsample_bytree = best_params['colsample_bytree'][0]
subsample = best_params['subsample'][0]
reg_alpha = best_params['reg_alpha'][0]
reg_lambda = best_params['reg_lambda'][0]


lgb_classifier_hyp = lgb.LGBMClassifier(objective = 'binary',
                                        max_depth = max_depth,
                                        n_estimators = n_estimators,
                                        learning_rate = learning_rate,
                                        min_child_weight = min_child_weight,
                                        min_child_samples = min_child_samples,
                                        num_eaves = num_leaves,
                                        colsample_bytree = colsample_bytree,
                                        subsample = subsample,
                                        reg_alpha = reg_alpha,
                                        reg_lambda = reg_lambda,                    
                                        is_unbalance = True,                                      
                                        seed=21,
                                        n_jobs=-1, 
                                        verbosity = -1).fit(X_train_best, y_res)
        
print_classification_metrics(lgb_classifier_hyp, X_train_best, y_res, X_test_best, y_test)


from catboost import CatBoostClassifier
from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score
import optuna
import catboost
from optuna_integration import CatBoostPruningCallback


# Consider StratifiedShuffleSplit for imbalanced classes
skf = StratifiedShuffleSplit(n_splits=5, random_state=21)

# Define the objective function with early stopping
def catboost_objective(trial):
    params = {
        'objective': 'Logloss',  
        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),
        'depth': trial.suggest_int('max_depth', 2, 10), 
        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 5e-1, log=False),        
        'num_leaves': trial.suggest_int('num_leaves', 10, 64),
        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),
        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 100.0, log=False),
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
        'random_strength': trial.suggest_int('random_strength', 1, 100),
        'subsample': trial.suggest_float("subsample", 0.5, 1.0, log=False),
        'random_seed': 21,
        'grow_policy': 'Lossguide',
        'boosting_type': 'Plain',
        'used_ram_limit': '4gb',        
        'silent':True,
        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.852, 1.870)        
    }

    scores = cross_val_score(CatBoostClassifier(**params), 
                             X_train_best, y_res, 
                             cv=skf, scoring='neg_log_loss', 
                            # n_jobs=-1,
                            )
    return -scores.mean()

    

# Create an Optuna study
study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),
                            direction='minimize')

# Optimize the objective function
optuna.logging.set_verbosity(optuna.logging.WARNING)

study.optimize(catboost_objective, 
               n_trials=100, 
               timeout=600, 
               show_progress_bar = True)

# Print the best hyperparameters and the corresponding score
print()
print("Best hyperparameters:", pd.DataFrame([study.best_params]).transpose())
print()
print("Best score (Minimum loss):", study.best_value)
print()


# Train the CatBoost model with the best hyperparameters
best_params = study.best_params
catboost_model = CatBoostClassifier(**best_params,
                                    objective = 'Logloss',
                                    grow_policy = 'Lossguide',
                                    silent = True,
                                    boosting_type = 'Plain',
                                    random_seed = 21,                                    
)

catboost_model.fit(X_train_best, y_res)

print_classification_metrics(catboost_model, X_train_best, y_res, X_test_best, y_test)


from catboost import CatBoostClassifier
from hyperopt import hp, fmin, tpe, STATUS_OK, Trials
from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score
import numpy as np
import sklearn

# Consider StratifiedShuffleSplit for imbalanced classes
skf = StratifiedShuffleSplit(n_splits=5, random_state=21)

# Define the hyperparameter search space
space = {
    'depth': hp.quniform('depth', 2, 10, 1), 
    'n_estimators': hp.choice('n_estimators', np.arange(100, 1001, dtype = int)),
    'learning_rate': hp.uniform('learning_rate', 0.0, 1.0),
    'max_leaves': hp.uniform('max_leaves', 10, 64),
    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 0, 100),
    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1.0),
    'min_data_in_leaf': hp.uniform("min_data_in_leaf", 5, 100), 
    'subsample': hp.uniform('subsample', 0.5, 1.0),
    'random_strength': hp.quniform('random_strength', 1, 100, 1),
    }

# Define the objective function with early stopping
def catboost_objective(params):
    classifier = CatBoostClassifier(        
        objective = 'Logloss',        
        depth = int(params['depth']),
        iterations = int(params['n_estimators']),
        learning_rate = params['learning_rate'],
        max_leaves = int(params['max_leaves']),
        l2_leaf_reg = params['l2_leaf_reg'],
        colsample_bylevel = params['colsample_bylevel'],
        min_data_in_leaf = params['min_data_in_leaf'],
        subsample = params['subsample'],
        random_strength = int(params['random_strength']),        
        random_state = 21,
        grow_policy = 'Lossguide',
        boosting_type = 'Plain',
        silent = True,
#thread_count = -1,  # Enable GPU if available

    )

    score = cross_val_score(classifier, 
                            X_train_best, y_res, 
                            cv=skf, 
                            scoring='neg_log_loss', 
                            #n_jobs=-1
                           )
    
    return {'loss': -score.mean(), 'status': STATUS_OK}
    
# Create a Trials object to track the optimization process
trials = Trials()

# Optimize the objective function using fmin
best = fmin(
    fn=catboost_objective,
    space=space,
    algo=tpe.suggest,
    max_evals=100,
    trials=trials,
    rstate=np.random.default_rng(21)
)

# Print the best hyperparameters and the corresponding score
print()
print("Best hyperparameters:", pd.DataFrame([best]).transpose())
print()
print("Best score:", trials.best_trial['result']['loss'])


# Retrieve the best hyperparameters
best_params = trials.best_trial['misc']['vals']

# Extract scalar values from the lists
colsample_bylevel = best_params['colsample_bylevel'][0]
depth = int(best_params['depth'][0])
learning_rate = best_params['learning_rate'][0]
max_leaves = int(best_params['max_leaves'][0])
min_data_in_leaf = int(best_params['min_data_in_leaf'][0])
l2_leaf_reg = best_params['l2_leaf_reg'][0]
n_estimators = best_params['n_estimators'][0]
random_strength = int(best_params['random_strength'][0])
subsample = best_params['subsample'][0]


# Create a new CatBoostClassifier instance with the best hyperparameters
best_model = CatBoostClassifier(
    objective='Logloss',
    colsample_bylevel=colsample_bylevel,
    depth=depth,
    learning_rate=learning_rate,
    max_leaves = max_leaves,
    min_data_in_leaf = min_data_in_leaf,
    l2_leaf_reg=l2_leaf_reg,
    n_estimators = n_estimators,    
    random_strength=random_strength,
    subsample=subsample,
    random_state=21,
    grow_policy = 'Lossguide',
    boosting_type = 'Plain',
    silent = True,      
)

# Train the best model on the resampled data
best_model.fit(X_train_best, y_res)

print_classification_metrics(catboost_model, X_train_best, y_res, X_test_best, y_test)



